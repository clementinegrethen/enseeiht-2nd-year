{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction à la librairie Keras"
      ],
      "metadata": {
        "id": "1qjWcjWFVcs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le TP précédent, vous avez implémenté l'apprentissage et l'inférence d'un réseau de neurones. En pratique, il est plus courant de faire appel à des librairies qui masquent la complexité de ces algorithmes (notamment le calcul des gradients, réalisé par différentiation automatique). Dans la suite, nous utiliserons pour les TPs la librairie ***Keras***. Dans un premier temps, pour ce TP nous allons détailler sur un exemple simple (le même que pour le TP précédent) les différentes étapes à mettre en place pour entraîner un réseau à l'aide de cette librairie."
      ],
      "metadata": {
        "id": "77ojmk9zVgUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemple de classification simple"
      ],
      "metadata": {
        "id": "b2Sq7AygNuNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Génération des données \n",
        "x, y = datasets.make_blobs(n_samples=250, n_features=2, centers=2, center_box=(- 3, 3), random_state=1)\n",
        "# Partitionnement des données en apprentissage et test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1)\n",
        "\n",
        "# Affichage des données d'apprentissage\n",
        "plt.plot(x_train[y_train==0,0], x_train[y_train==0,1], 'b.')\n",
        "plt.plot(x_train[y_train==1,0], x_train[y_train==1,1], 'r.')\n",
        "\n",
        "# Affichage des données de test\n",
        "plt.plot(x_test[y_test==0,0], x_test[y_test==0,1], 'b+')\n",
        "plt.plot(x_test[y_test==1,0], x_test[y_test==1,1], 'r+')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "luY3XIU7WfWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Définition du modèle, auquel on va ensuite ajouter les différentes couches, dans l'ordre\n",
        "# NB: c'est exactement ce que nous avons implémenté avec le perceptron multicouche dans le\n",
        "# TP précédent ! \n",
        "model = Sequential()\n",
        "model.add(Dense(1, activation='sigmoid', input_dim=2)) # input_dim indique la dimension de la couche d'entrée, ici 2\n",
        "\n",
        "model.summary() # affiche un résumé du modèle"
      ],
      "metadata": {
        "id": "lTGP4a9WXWpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "# Définition de l'optimiseur\n",
        "sgd = optimizers.SGD(learning_rate=0.1) # On choisit la descente de gradient stochastique, avec un taux d'apprentissage de 0.1\n",
        "\n",
        "# On définit ici, pour le modèle introduit plus tôt, l'optimiseur choisi, la fonction de perte (ici\n",
        "# l'entropie croisée binaire pour un problème de classification binaire) et les métriques que l'on veut observer pendant\n",
        "# l'entraînement. La précision (accuracy) est un indicateur plus simple à interpréter que l'entropie croisée.\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle avec des mini-batchs de taille 20, sur 15 epochs. \n",
        "# Le paramètre validation_split signifie qu'on tire aléatoirement une partie des données\n",
        "# (ici 20%) pour servir d'ensemble de validation\n",
        "history = model.fit(x_train, y_train, validation_split=0.2, epochs=15, batch_size=20)"
      ],
      "metadata": {
        "id": "nZEDm5I-Lu-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La cellule suivante introduit un code permettant de visualiser la frontière de décision du modèle appris. "
      ],
      "metadata": {
        "id": "fD8fXJj0WJID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def print_decision_boundaries(model, x, y):\n",
        "  dx, dy = 0.1, 0.1\n",
        "  y_grid, x_grid = np.mgrid[slice(np.min(x[:,1]), np.max(x[:,1]) + dy, dy),\n",
        "                  slice(np.min(x[:,0]), np.max(x[:,0]) + dx, dx)]\n",
        "\n",
        "\n",
        "  x_gen = np.concatenate((np.expand_dims(np.reshape(x_grid, (-1)),1),np.expand_dims(np.reshape(y_grid, (-1)),1)), axis=1)\n",
        "  z_gen = model.predict(x_gen).reshape(x_grid.shape)\n",
        "\n",
        "  z_min, z_max = 0, 1\n",
        "\n",
        "  c = plt.pcolor(x_grid, y_grid, z_gen, cmap='RdBu', vmin=z_min, vmax=z_max)\n",
        "  plt.colorbar(c)\n",
        "  plt.plot(x[y==0,0], x[y==0,1], 'r.')\n",
        "  plt.plot(x[y==1,0], x[y==1,1], 'b.')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "8iSYRgNaL6F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_decision_boundaries(model, x_train, y_train)"
      ],
      "metadata": {
        "id": "ltsUweGrMPor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemple de classification plus \"complexe\""
      ],
      "metadata": {
        "id": "mSaSWEnoNxqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour manipuler un peu la librairie, voici un second problème légèrement plus complexe. A vous de réutiliser les cellules précédentes pour mettre en place un réseau permettant de résoudre ce problème."
      ],
      "metadata": {
        "id": "W60rDDAzWTpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = datasets.make_gaussian_quantiles(n_samples=250, n_features=2, n_classes=2, random_state=1)\n",
        "# Partitionnement des données en apprentissage et test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1)\n",
        "\n",
        "# Affichage des données d'apprentissage\n",
        "plt.plot(x_train[y_train==0,0], x_train[y_train==0,1], 'b.')\n",
        "plt.plot(x_train[y_train==1,0], x_train[y_train==1,1], 'r.')\n",
        "\n",
        "# Affichage des données de test\n",
        "plt.plot(x_test[y_test==0,0], x_test[y_test==0,1], 'b+')\n",
        "plt.plot(x_test[y_test==1,0], x_test[y_test==1,1], 'r+')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KvhN3uQaN5ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMMppWbnG3dN"
      },
      "source": [
        "# Classification d'images de chiens et de chats\n",
        "\n",
        "Dans la suite du TP, on s'intéresse au problème simple (en apparence) de reconnaître des chiens et des chats dans des images.\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=11W1SmzrBhL8vyzPCjSkZfHWnxb7kByi5\" style=\"width:1000;height:550px;\"></center>\n",
        "<caption><center><b> Figure 1 : Quelques images de la base de données </b></center></caption>\n",
        "\n",
        "Pour cela nous allons utiliser une base de données de 4000 images, réparties en 2000 images d'apprentissage, 1000 images de validation, et 1000 images de test. Compte-tenu de la variabilité possible des représentations de chiens et chats, cette base de données est d'une taille assez réduite et le problème est complexe. Il correspond bien aux problèmes que nous pouvons rencontrer dans la réalité, lorsque les données sont souvent difficiles à obtenir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il faut définir une résolution commune à toutes les images, qui sera donc la dimension passée en entrée au réseau de neurones. Pour commencer et simplifier le problème, vous pouvez d'abord considérer des images de taille $64 \\times 64$ ; plus tard, lorsque vos réseaux fonctionneront bien, nous pourrons envisager d'augmenter cette résolution pour améliorer les performances.  "
      ],
      "metadata": {
        "id": "m7K-oLcaXkcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 64\n",
        "CLASSES = ['cat', 'dog']"
      ],
      "metadata": {
        "id": "8th8b32kV2kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3mdNJJXc6Wy"
      },
      "source": [
        "## Chargement des données\n",
        "La base de données est à télécharger depuis Git. Ne passez pas trop de temps à regarder les cellules suivantes (mais exécutez les !)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_OkpjrpFXXG"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/axelcarlier/iam.git\n",
        "path = \"./iam/tp3/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoSVj5OGXa-4"
      },
      "source": [
        "Chargement des données dans des tenseurs $x$ et $y$ de dimensions respectives $(N, 64, 64, 3)$ et $(N, 1)$, où $N$ désigne le nombre d'éléments de l'ensemble considéré (apprentissage, validation, ou test)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_data(path, classes, image_size=64):\n",
        "\n",
        "  # Liste les fichiers présents dans le dossier path\n",
        "  file_path = glob.glob(path)\n",
        "  \n",
        "  # Initialise les structures de données\n",
        "  x = np.zeros((len(file_path), image_size, image_size, 3))\n",
        "  y = np.zeros((len(file_path), 1))\n",
        "\n",
        "  for i in range(len(file_path)):\n",
        "    # Lecture de l'image\n",
        "    img = Image.open(file_path[i])\n",
        "    # Mise à l'échelle de l'image\n",
        "    img = img.resize((image_size,image_size), Image.ANTIALIAS)\n",
        "    # Remplissage de la variable x\n",
        "    x[i] = np.asarray(img)\n",
        "\n",
        "    img_path_split = file_path[i].split('/')\n",
        "    img_name_split = img_path_split[-1].split('.')\n",
        "    class_label = classes.index(img_name_split[-3])\n",
        "    \n",
        "    y[i] = class_label\n",
        "\n",
        "  return x, y\n",
        "\n",
        "x_train, y_train = load_data('./iam/tp3/train/*', CLASSES, image_size=IMAGE_SIZE)\n",
        "x_val, y_val = load_data('./iam/tp3/validation/*', CLASSES, image_size=IMAGE_SIZE)\n",
        "x_test, y_test = load_data('./iam/tp3/test/*', CLASSES, image_size=IMAGE_SIZE)\n",
        "\n",
        "# Normalisation des entrées via une division par 255 des valeurs de pixel.\n",
        "x_train = x_train/255\n",
        "x_val = x_val/255\n",
        "x_test = x_test/255"
      ],
      "metadata": {
        "id": "VcNp4xl0QfOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwngS1p9V1VN"
      },
      "source": [
        "### Visualisation des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXUxcuIPOS5W"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Randomisation des indices et affichage de 9 images alétoires de la base d'apprentissage\n",
        "indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(0, 9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.title(CLASSES[int(y_train[i])])\n",
        "    plt.imshow(x_train[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV5s1T3yWJB6"
      },
      "source": [
        "## Première approche : réseau convolutif de base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00T5cUGlif9z"
      },
      "source": [
        "Les images ont toutes été redimensionnées en $64 \\times 64$. \n",
        "Vous devez définir un réseau de neurones convolutif en suivant ce schéma pour la base convolutive : \n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1bwXaIgO-pKJGs6fVaX0IrLbFbUAlTvNM\" style=\"width:800;height:400px;\"></center>\n",
        "<caption><center><b> Figure 2: Vue de l'architecture à implémenter </b></center></caption>\n",
        "\n",
        "Ce réseau alterne dans une première phase les couches de convolution et de Max Pooling (afin de diviser à chaque fois la dimension des tenseurs par 2). \n",
        "\n",
        "La première couche comptera 32 filtres de convolution, la seconde 64, la troisième 96 et la 4e 128. Enfin, avant la couche de sortie, vous ajouterez une couche dense comptant 512 neurones. Vous aurez donc construit un réseau à 6 couches, sorte de version simplifiée d'AlexNet.\n",
        "\n",
        "Pour construire ce réseau, vous pouvez utiliser les fonctions Conv2D, Maxpooling2D, et Flatten de Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktYvE7Poiyhm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "# A COMPLETER\n",
        "# model.add(Conv2D(...))\n",
        "# model.add(MaxPooling2D(..))\n",
        "# ...\n",
        "# model.add(Flatten())    # \"Mise à plat\" (vectorisation) du tenseur pour permettre de la connecter à une couche dense  \n",
        "# model.add(Dense(...))   # Couche dense, à 512 neurones\n",
        "# model.add(Dense(...))   # Couche de sortie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtQwoedfbvk0"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWqVtzWZIsOY"
      },
      "source": [
        "### Entrainement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q9IQIETzLI-"
      },
      "source": [
        "Pour l'entraînement, vous pouvez utiliser directement les hyperparamètres suivants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJsJ7mMIjCGm"
      },
      "outputs": [],
      "source": [
        "# COMPLETER LA FONCTION DE COUT A UTILISER\n",
        "model.compile(loss=...,\n",
        "              optimizer=optimizers.Adam(learning_rate=3e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNbGxTZt4cck"
      },
      "source": [
        "... puis lancer l'entraînement. **Attention : si jamais vous voulez relancer l'entraînement, il faut réinitialiser les poids du réseau. Pour cela il faut re-exécuter les cellules précédentes à partir de la définition du réseau !** Sinon vous risquez de repartir d'un entraînement précédent (qui s'est éventuellement bien, ou mal déroulé) et mal interpréter votre nouvel entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjetcQRljJC8"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBPk-patWSYX"
      },
      "source": [
        "### Analyse des résultats du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "casoAuXmzWYb"
      },
      "source": [
        "Les quelques lignes suivantes permettent d'afficher l'évolution des métriques au cours de l'entraînement, sur les ensembles d'apprentissage et de validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fExCbSI3V6Ur"
      },
      "outputs": [],
      "source": [
        "def plot_training_analysis():\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'b', linestyle=\"--\",label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', linestyle=\"--\",label='Training loss')\n",
        "  plt.plot(epochs, val_loss,'g', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex3AjPOPu2UN"
      },
      "outputs": [],
      "source": [
        "plot_training_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ochTgkyqwHIe"
      },
      "source": [
        "### Correction du surapprentissage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXb2ZxKv4gpi"
      },
      "source": [
        "Vous devriez reconnaître le problème auquel vous avez affaire : **le surapprentissage**. Ce problème est classique dès lors que l'on travaille sur des bases de données de taille réduite en apprentissage profond.\n",
        " En effet, le réseau que vous avez créé compte normalement (si vous avez suivi les indications) plusieurs centaines de milliers de paramètres. Le problème que vous essayez de résoudre pendant l'entraînement consiste à établir 450 000 paramètres avec seulement 2000 exemples : c'est trop peu !\n",
        "\n",
        "Afin de limiter ce surapprentissage, nous pouvons appliquer les techniques de régularisation vues pendant le 2nd cours. En traitement d'image, une des techniques les plus couramment utilisées est **l'augmentation de la base de données**.\n",
        "\n",
        "Nous allons introduire un objet *ImageDataGenerator* pour appliquer des transformations supplémentaires aux images de notre base de données. A vous de chercher dans la documentation à quoi correspondent les différents paramètres présentés ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90Wlyt6Gwm6v"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkZEqml-4ccl"
      },
      "source": [
        "La cellule suivante vous permet de visualiser des images passées à travers notre boucle d'augmentation de données. Observez comment les valeurs manquantes (par exemple, dans le cas d'une rotation) sont comblées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqDBaNs94ccm"
      },
      "outputs": [],
      "source": [
        "example_x, example_y = train_datagen.flow(x_train, y_train, batch_size=1).next()\n",
        "for i in range(0,1):\n",
        "    plt.imshow(example_x[i])\n",
        "    plt.title(CLASSES[int(example_y[i])])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdqsPbKm5TkR"
      },
      "source": [
        "Nous pouvons maintenant recréer notre modèle et relancer l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJLABQ67yLms"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# A COMPLETER\n",
        "# RECOPIER LE MODELE PRECEDENT\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# AJOUTER EGALEMENT LA FONCTION DE COUT\n",
        "model.compile(loss=...,\n",
        "              optimizer=optimizers.Adam(learning_rate=3e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_datagen.flow(x_train, y_train, batch_size=10), \n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=50,\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM2CLNX8wbfv"
      },
      "source": [
        "### Analyse des résultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9smZiILLyt8g"
      },
      "outputs": [],
      "source": [
        "plot_training_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_JbNoF46le7"
      },
      "source": [
        "On voit clairement sur les courbes que l'on a limité le sur-apprentissage. Notez aussi d'ailleurs, et c'est important, que l'apprentissage est plus lent : le modèle met plus de temps à prédire correctement l'ensemble d'apprentissage. C'est normal, car on a en quelque sorte \"complexifié le problème\" en introduisant toutes ces déformations de nos images.\n",
        "Cette forme de régularisation \"par les données\" s'ajoute aux autres méthodes que nous avons vues précédemment comme la régularisation L1/L2 des poids du réseau et le Dropout.  \n",
        "\n",
        "Vous devriez maintenant atteindre des performances autour de 80% de précision sur l'ensemble de validation, ce qui est bien mais pas complètement satisfaisant : il faudrait pour continuer à s'améliorer probablement s'entraîner plus longtemps, mais également disposer de plus de données.\n",
        "\n",
        "Une autre solution est d'utiliser le **Transfer Learning**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVFqfXs9GrKe"
      },
      "source": [
        "## Transfer learning\n",
        "\n",
        "L'une des raisons qui peut expliquer le fait que nos résultats soient décevants est que les premières couches de notre réseau convolutif, sensées détecter des caractéristiques utiles pour discriminer chiens et chats, n'ont pas appris de filtres suffisamment généraux à partir des 2000 images d'entraînement. Ainsi, même si ces filtres sont pertinents pour les 2000 images d'entraînement, il y a en fait assez peu de chances que ces filtres puissent bien fonctionner pour la généralisation sur de nouvelles données.\n",
        "\n",
        "C'est la raison pour laquelle nous avons envie de réutiliser un réseau pré-entrainé sur une large base de données, permettant donc de détecter des caractéristiques qui généraliseront mieux à de nouvelles données.\n",
        "\n",
        "Dans cette partie, nous allons réutiliser un réseau célèbre, et d'ores et déjà entraîné sur la base de données ImageNet : le réseau VGG-16.\n",
        "\n",
        "Commençons par récupérer les couches de convolution de ce réseau, et s'en remémorer  la composition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRWY8mEQuF9O"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet', # On utilise les poids du réseau déjà pré-entrainé sur la base de données ImageNet\n",
        "                  include_top=False, # On ne conserve pas la partie Dense du réseau originel\n",
        "                  input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv_jCMwkuHY4"
      },
      "outputs": [],
      "source": [
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKyLfZcwOYwH"
      },
      "source": [
        "Nous pouvons extraire les caractéristiques, apprises par le réseau de neurones sur ImageNet, de notre base de données d'image de chiens et de chat. L'intérêt, par rapport à la première partie, est qu'il aurait été presque impossible de déduire ces caractéristiques \"générales\" (trouvées sur une immense base de données) depuis notre base de données trop réduite de 2000 images. En revanche, ces caractéristiques générales devraient se révéler utiles pour notre classifieur.\n",
        "\n",
        "On peut lire sur la structure du réseau VGG résumée grâce à la fonction *summary* ci-dessus que le tenseur de sortie est de dimension $2 \\times 2 \\times 512$, autrement dit que le réseau prédit des caractéristiques de dimension $2 \\times 2 \\times 512$ à partir d'une image de taille $64 \\times 64$.\n",
        "\n",
        "On va redimensionner cette sortie dans un vecteur de dimension $2048 = 2 \\times 2 \\times 512$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op4vvD9_ugWL"
      },
      "outputs": [],
      "source": [
        "train_features = conv_base.predict(x_train)\n",
        "train_features = np.reshape(train_features,(train_features.shape[0],2*2*512))\n",
        "\n",
        "val_features = conv_base.predict(x_val)\n",
        "val_features = np.reshape(val_features,(val_features.shape[0],2*2*512))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A_ayR0dvvwe"
      },
      "source": [
        "Nous pouvons maintenant définir un réseau de neurones simple (par exemple, de 2 couches denses, avec 256 neurones sur la couche cachée)  qui va travailler directement sur les caractéristiques prédites par VGG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmmBYYmtvUUF"
      },
      "outputs": [],
      "source": [
        "# A COMPLETER\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# AJOUTER EGALEMENT LA FONCTION DE COUT\n",
        "model.compile(optimizer=optimizers.Adam(lr=3e-4),\n",
        "              loss=...,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# COMPLETER AVEC LES TENSEURS SUR LESQUELS EFFECTUER L'APPRENTISSAGE\n",
        "history = model.fit(..., ...,\n",
        "                    epochs=50,\n",
        "                    batch_size=16,\n",
        "                    validation_data=(..., ...))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5xpyZCS4cco"
      },
      "outputs": [],
      "source": [
        "plot_training_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CFd7e-dJ-cK"
      },
      "source": [
        "On observe à nouveau beaucoup de sur-apprentissage. Il faudrait trouver un moyen d'intégrer de l'augmentation de données. \n",
        "\n",
        "Pour cela, on peut connecter notre petit réseau de neurones à l'extrémité de la base convolutionnelle de VGG. L'idée est qu'en réutilisant notre générateur de données augmentées, nous pourrons calculer les caractéristiques de VGG sur les données augmentées, et ainsi classifier ces caractéristiques plutôt que les caractéristiques de notre base de données uniquement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W85VMorXPtP"
      },
      "source": [
        "## Intégration de l'augmentation de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCb_itsuXenK"
      },
      "source": [
        "### Définition du nouveau modèle et entrainement\n",
        "\n",
        "On commence par créer un nouveau modèle qui va s'appuyer sur la base convolutive de VGG, à laquelle on adjoint une couche dense et notre couche de sortie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyZZS-GSKyPZ"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZr_u4s7K4Fi"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRiiu2EbBNAv"
      },
      "source": [
        "**Attention** : il est important de ne pas commander l'entraînement de la base convolutionnelle de VGG ! Nous ne voulons en aucun cas écraser les bonnes caractéristiques de VGG que nous cherchons justement à réutiliser ! Le réseau aurait en outre un grand nombre de paramètres, ce qui est justement ce que l'on veut éviter ! \n",
        "\n",
        "Pour cela nous pouvons utiliser l'attribut *trainable* : en le positionnant à *false*, nous pouvons geler les poids et en empêcher la mise à jour pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h8Fx8P0PId5"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = False\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7tkMrA14ccp"
      },
      "source": [
        "Observez le décompte des poids : le nombre de poids entraînable est maintenant de 500 000, contre 16 millions précédemment ; on ne va entrainer ici que les poids de notre couche dense et de la couche de sortie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go7Uld7sLRdG"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=3e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_datagen.flow(x_train, y_train, batch_size=10), \n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=10,\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-RNeMcAXu8h"
      },
      "source": [
        "### Analyse des résultats du nouveau modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJWBzO-KCCSh"
      },
      "source": [
        "L'entraînement est beaucoup plus lent ! Il faut en effet générer les données augmentées, et leur faire traverser les couches de VGG à chaque itération de gradient. Ceci prend du temps !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DHOFSauLyJa"
      },
      "outputs": [],
      "source": [
        "plot_training_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac4pNlvJCtkY"
      },
      "source": [
        "En revanche, on observe que l'on a bien limité le sur-apprentissage, ce qui était le but recherché. Les résultats sont un peu meilleurs mais pas complètement satisfaisants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmykKP9_M1GW"
      },
      "source": [
        "### Fine-tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4pV9QlhFc_8"
      },
      "source": [
        "Nous pouvons maintenant tester la dernière technique vue en cours : le **fine-tuning**. Pour cela, nous allons repartir du réseau que nous venons d'entraîner, mais nous allons débloquer l'entraînement des poids de l'ensemble du réseau. **ATTENTION : il est important de choisir un taux d'apprentissage très faible afin de ne pas réduire à néant les bénéfices des entraînements précédents.** L'objectif est simplement de faire évoluer les paramètres du réseau \"à la marge\", et ceci ne peut être fait qu'après la première étape de *transfer learning* précédente. Sans cela, les dernières couches ajoutées à la suite de la base convolutive, après leur initialisation aléatoire, auraient engendré de forts gradients qui auraient complètement détruit les filtres généraux de VGG.\n",
        "\n",
        "\n",
        "\n",
        "On commence par réactiver l'entraînement des paramètres de la base convolutive de VGG : "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeZA3eVYEJDY"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9SvUKcWEPVd"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=1e-5), # Taux d'apprentissage réduit pour ne pas tout casser, ni risquer le sur-apprentissage !\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_datagen.flow(x_train, y_train, batch_size=10), \n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=10,\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCK-hm_IN0P4"
      },
      "outputs": [],
      "source": [
        "plot_training_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hCLsD6tpGhm"
      },
      "source": [
        "On atteint un bon résultat, proche des 90% de précision sur l'ensemble de validation, bien au-dessus des performances obtenues sans *transfer learning* ! Vous comprenez maintenant pourquoi en traitement d'image, cette technique est incontournable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VptFMmkArNqi"
      },
      "source": [
        "**S'il vous reste du temps** :\n",
        "\n",
        "Vous pouvez maintenant reprendre le travail depuis le début en augmentant la résolution des images (par exemple $128 \\times 128$). A l'issue du *transfer learning* et du *fine-tuning*, vous devriez dépasser les 95\\% de précision sur l'ensemble de validation. \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}